{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "os.chdir('../data')\n",
    "with open('raw_text.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "keys = list(data.keys())\n",
    "random.shuffle(keys)\n",
    "train_keys = keys[:80]\n",
    "test_keys = keys[80:]\n",
    "train_data = {key: data[key] for key in train_keys}\n",
    "test_data = {key: data[key] for key in test_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = []\n",
    "train_story_names = []\n",
    "test_texts = []\n",
    "test_story_names = []\n",
    "\n",
    "for name, sequence in train_data.items():\n",
    "    try:\n",
    "        text = sequence.data\n",
    "        text = ' '.join(text)\n",
    "        train_texts.append(text)\n",
    "        train_story_names.append(name)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract text for {name}: {e}\")\n",
    "\n",
    "for name, sequence in test_data.items():\n",
    "    try:\n",
    "        text = sequence.data\n",
    "        text = ' '.join(text)\n",
    "        test_texts.append(text)\n",
    "        test_story_names.append(name)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract text for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading pretrained Word2Vec from gensim...\n",
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "Loaded Word2Vec with 400000 words, vector size = 100\n"
     ]
    }
   ],
   "source": [
    "# Chunk 1: Load pretrained Word2Vec and prepare word-level matrix\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load small pretrained word2vec model\n",
    "print(\"⏳ Loading pretrained Word2Vec from gensim...\")\n",
    "w2v = api.load(\"word2vec-google-news-300\")  # Fast & decent\n",
    "print(f\"Loaded Word2Vec with {len(w2v.key_to_index)} words, vector size = {w2v.vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../code')\n",
    "import preprocessing as prep\n",
    "\n",
    "TR_DURATION = 2\n",
    "delays = [1, 2, 3, 4]\n",
    "\n",
    "# Paths\n",
    "subject_dirs = [\n",
    "    \"/ocean/projects/mth240012p/shared/data/subject2\",\n",
    "    \"/ocean/projects/mth240012p/shared/data/subject3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word2vec_dic = {}\n",
    "for name, ds in train_data.items():\n",
    "    try:\n",
    "        # Get word list\n",
    "        word_list = ds.data.tolist() if isinstance(ds.data, np.ndarray) else ds.data\n",
    "        vectors = []\n",
    "\n",
    "        for word in word_list:\n",
    "            if word in w2v:\n",
    "                vectors.append(w2v[word])\n",
    "            else:\n",
    "                vectors.append(np.zeros(w2v.vector_size))  # fallback if OOV\n",
    "\n",
    "        word_matrix = np.stack(vectors)  # shape: (num_words, embedding_dim)\n",
    "\n",
    "        # Downsample to TR resolution\n",
    "        downsampled = prep.downsample_word_vectors(\n",
    "            stories=[name],\n",
    "            word_vectors={name: word_matrix},\n",
    "            wordseqs={name: ds}\n",
    "        )[name]\n",
    "\n",
    "        # Trim 5s from start and 10s from end\n",
    "        trimmed = downsampled[5 : -10, :]\n",
    "\n",
    "        # Create delayed embedding\n",
    "        delayed = prep.make_delayed(trimmed, delays)\n",
    "        train_word2vec_dic[name] = delayed\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word2vec_dic = {}\n",
    "for name, ds in test_data.items():\n",
    "    try:\n",
    "        # Get word list\n",
    "        word_list = ds.data.tolist() if isinstance(ds.data, np.ndarray) else ds.data\n",
    "        vectors = []\n",
    "\n",
    "        for word in word_list:\n",
    "            if word in w2v:\n",
    "                vectors.append(w2v[word])\n",
    "            else:\n",
    "                vectors.append(np.zeros(w2v.vector_size))  # fallback if OOV\n",
    "\n",
    "        word_matrix = np.stack(vectors)  # shape: (num_words, embedding_dim)\n",
    "\n",
    "        # Downsample to TR resolution\n",
    "        downsampled = prep.downsample_word_vectors(\n",
    "            stories=[name],\n",
    "            word_vectors={name: word_matrix},\n",
    "            wordseqs={name: ds}\n",
    "        )[name]\n",
    "\n",
    "        # Trim 5s from start and 10s from end\n",
    "        trimmed = downsampled[5 : -10, :]\n",
    "\n",
    "        # Create delayed embedding\n",
    "        delayed = prep.make_delayed(trimmed, delays)\n",
    "        test_word2vec_dic[name] = delayed\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 400)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word2vec_dic['sweetaspie'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
