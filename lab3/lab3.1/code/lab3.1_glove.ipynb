{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruiwe\\AppData\\Local\\Temp\\ipykernel_44328\\2690323908.py:6: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  data = pickle.load(file)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "os.chdir('../data')\n",
    "with open('raw_text.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "keys = list(data.keys())\n",
    "random.shuffle(keys)\n",
    "train_keys = keys[:80]\n",
    "test_keys = keys[80:]\n",
    "train_data = {key: data[key] for key in train_keys}\n",
    "test_data = {key: data[key] for key in test_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = []\n",
    "train_story_names = []\n",
    "test_texts = []\n",
    "test_story_names = []\n",
    "\n",
    "for name, sequence in train_data.items():\n",
    "    try:\n",
    "        text = sequence.data\n",
    "        text = ' '.join(text)\n",
    "        train_texts.append(text)\n",
    "        train_story_names.append(name)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract text for {name}: {e}\")\n",
    "\n",
    "for name, sequence in test_data.items():\n",
    "    try:\n",
    "        text = sequence.data\n",
    "        text = ' '.join(text)\n",
    "        test_texts.append(text)\n",
    "        test_story_names.append(name)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract text for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Your local download path\n",
    "glove_dir = \"../data/glove\"\n",
    "glove_zip = os.path.join(glove_dir, \"glove.6B.zip\")\n",
    "glove_txt = os.path.join(glove_dir, \"glove.6B.100d.txt\")\n",
    "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GloVe to your lab3 directory...\n",
      "Unzipping GloVe...\n",
      "GloVe download complete.\n"
     ]
    }
   ],
   "source": [
    "# Download if GloVe not already present\n",
    "if not os.path.exists(glove_txt):\n",
    "    print(\"Downloading GloVe to your directory...\")\n",
    "    r = requests.get(glove_url, stream=True)\n",
    "    with open(glove_zip, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    print(\"Unzipping GloVe...\")\n",
    "    with zipfile.ZipFile(glove_zip, \"r\") as zip_ref:\n",
    "        zip_ref.extract(\"glove.6B.100d.txt\", path=glove_dir)\n",
    "\n",
    "    print(\"GloVe download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe with 400000 words, dim = 100\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe vectors into dict\n",
    "glove = {}\n",
    "with open(glove_txt, 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        word = parts[0]\n",
    "        vec = np.array(parts[1:], dtype=np.float32)\n",
    "        glove[word] = vec\n",
    "\n",
    "print(f\"Loaded GloVe with {len(glove)} words, dim = {vec.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../code')\n",
    "import preprocessing as prep\n",
    "\n",
    "TR_DURATION = 2\n",
    "delays = [1, 2, 3, 4]\n",
    "\n",
    "# Paths\n",
    "subject_dirs = [\n",
    "    \"/ocean/projects/mth240012p/shared/data/subject2\",\n",
    "    \"/ocean/projects/mth240012p/shared/data/subject3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glove_dic = {}\n",
    "for story, ds in train_data.items():\n",
    "    try:\n",
    "        if not hasattr(ds, \"data\") or not hasattr(ds, \"data_times\") or not hasattr(ds, \"tr_times\"):\n",
    "            print(f\"⚠️ Skipping {story}: missing attributes\")\n",
    "            continue\n",
    "\n",
    "        # Build GloVe matrix\n",
    "        glove_matrix = []\n",
    "        for tokens in ds.data:\n",
    "            vecs = [glove[word] for word in tokens if word in glove]\n",
    "            if vecs:\n",
    "                glove_matrix.append(np.mean(vecs, axis=0))\n",
    "            else:\n",
    "                glove_matrix.append(np.zeros(100))  # Assuming GloVe dim = 100\n",
    "\n",
    "        word_matrix = np.stack(glove_matrix)  # (num_words, 100)\n",
    "\n",
    "        # Downsample\n",
    "        downsampled = prep.downsample_word_vectors(\n",
    "            stories=[story],\n",
    "            word_vectors={story: word_matrix},\n",
    "            wordseqs={story: ds}\n",
    "        )[story]\n",
    "\n",
    "        # Trim\n",
    "        trimmed = downsampled[5 : -10, :]\n",
    "\n",
    "\n",
    "        delayed = prep.make_delayed(trimmed, delays)\n",
    "        train_glove_dic[story] = delayed\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {story}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_glove_dic = {}\n",
    "for story, ds in test_data.items():\n",
    "    try:\n",
    "        if not hasattr(ds, \"data\") or not hasattr(ds, \"data_times\") or not hasattr(ds, \"tr_times\"):\n",
    "            print(f\"⚠️ Skipping {story}: missing attributes\")\n",
    "            continue\n",
    "\n",
    "        # Build GloVe matrix\n",
    "        glove_matrix = []\n",
    "        for tokens in ds.data:\n",
    "            vecs = [glove[word] for word in tokens if word in glove]\n",
    "            if vecs:\n",
    "                glove_matrix.append(np.mean(vecs, axis=0))\n",
    "            else:\n",
    "                glove_matrix.append(np.zeros(100))  # Assuming GloVe dim = 100\n",
    "\n",
    "        word_matrix = np.stack(glove_matrix)  # (num_words, 100)\n",
    "\n",
    "        # Downsample\n",
    "        downsampled = prep.downsample_word_vectors(\n",
    "            stories=[story],\n",
    "            word_vectors={story: word_matrix},\n",
    "            wordseqs={story: ds}\n",
    "        )[story]\n",
    "\n",
    "        # Trim\n",
    "        trimmed = downsampled[5 : -10, :]\n",
    "\n",
    "\n",
    "        delayed = prep.make_delayed(trimmed, delays)\n",
    "        test_glove_dic[story] = delayed\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR processing {story}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 400)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_glove_dic['sweetaspie'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
